{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patriziodegirolamo/Esame-Questionario/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the dataset from drive.\n",
        "( You can find the zipped folder [here](https://drive.google.com/file/d/1XsRmyQYHfgRFJCOueXpJ37yyOCrKHO-W/view?usp=sharing))"
      ],
      "metadata": {
        "id": "Y9D12pC0R_eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/gdrive/')\n",
        "data_path = \"/content/data\"\n",
        "\n",
        "\n",
        "if not os.path.isfile('/content/data.zip'):\n",
        "  !gdown --id 1XsRmyQYHfgRFJCOueXpJ37yyOCrKHO-W # 3-5 min\n",
        "  !jar xf  \"/content/data.zip\"\n",
        "\n",
        "if not os.path.isdir('/content/data'):\n",
        "  print(\"Dataset doesn't exist\")\n",
        "\n"
      ],
      "metadata": {
        "id": "YOzT4IA9ZnnX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a9e7632-3ded-4b39-be10-2195cc0deb3d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive/; to attempt to forcibly remount, call drive.mount(\"/gdrive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp -r /content/data /gdrive/MyDrive/"
      ],
      "metadata": {
        "id": "R7nKbcbsPpnu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cloning the repository from github"
      ],
      "metadata": {
        "id": "e1nqqrU5SIBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the entire repo.\n",
        "repo_path = \"/content/cloned-repo\"\n",
        "if not os.path.isdir(repo_path):\n",
        "  !git clone -l -s git://github.com/CRosero/aml-project.git cloned-repo\n",
        "  %cd cloned-repo\n",
        "else:\n",
        "  print(\"Repository already cloned\")\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uzIXW9Z5Kl4",
        "outputId": "5474ec12-42a9-4f5a-eab9-e926384ea279"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repository already cloned\n",
            "/content/cloned-repo\n",
            "dataset     eval.py  model\t  README.md  train.ipynb  utils.py\n",
            "eval.ipynb  loss.py  __pycache__  runs\t     train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the libraries"
      ],
      "metadata": {
        "id": "A4np6uwUgDMW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QYHTsZf6SkxK"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from model.build_BiSeNet import BiSeNet\n",
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from utils import poly_lr_scheduler\n",
        "from utils import reverse_one_hot, compute_global_accuracy, fast_hist, per_class_iu\n",
        "from loss import DiceLoss\n",
        "import torch.cuda.amp as amp\n",
        "import os\n",
        "import os.path as osp\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import collections\n",
        "import torchvision\n",
        "from torchvision.transforms import InterpolationMode\n",
        "from torch.utils import data\n",
        "from PIL import Image\n",
        "import json\n",
        "# Dataset class:\n",
        "from dataset.cityscapesDataSet import cityscapesDataSet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load TensorBoard notebook extension\n",
        "#%load_ext tensorboard"
      ],
      "metadata": {
        "id": "n9TWPNCay2Md"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## -- VALIDATION --\n",
        "\n",
        "def val(args, model, dataloader):\n",
        "    print('start val!')\n",
        "    # label_info = get_label_info(csv_path)\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        precision_record = []\n",
        "        hist = np.zeros((args.num_classes, args.num_classes))\n",
        "        for i, (data, label) in enumerate(dataloader):\n",
        "            label = label.type(torch.LongTensor)\n",
        "            print(\"data shape before cuda\", data.shape)\n",
        "            \n",
        "            if torch.cuda.is_available() and args.use_gpu:\n",
        "                data = data.cuda()\n",
        "                label = label.cuda()\n",
        "            #data = data.cuda()\n",
        "            #label = label.long().cuda()\n",
        "            print(\"data shape\", data.shape)\n",
        "\n",
        "            # get RGB predict image\n",
        "            predict = model(data).squeeze()\n",
        "            print(\"before reverse one hot\", predict.shape)\n",
        "            predict = reverse_one_hot(predict)\n",
        "            predict = np.array(predict.cpu())\n",
        "\n",
        "            # get RGB label image\n",
        "            label = label.squeeze()\n",
        "            if args.loss == 'dice':\n",
        "                label = reverse_one_hot(label)\n",
        "            label = np.array(label.cpu())\n",
        "\n",
        "            # compute per pixel accuracy\n",
        "            precision = compute_global_accuracy(predict, label)\n",
        "            hist += fast_hist(label.flatten(), predict.flatten(), args.num_classes)\n",
        "\n",
        "            # there is no need to transform the one-hot array to visual RGB array\n",
        "            # predict = colour_code_segmentation(np.array(predict), label_info)\n",
        "            # label = colour_code_segmentation(np.array(label), label_info)\n",
        "            precision_record.append(precision)\n",
        "        \n",
        "        precision = np.mean(precision_record)\n",
        "        # miou = np.mean(per_class_iu(hist))\n",
        "        miou_list = per_class_iu(hist)[:-1]\n",
        "        # miou_dict, miou = cal_miou(miou_list, csv_path)\n",
        "        miou = np.mean(miou_list)\n",
        "        print('precision per pixel for test: %.3f' % precision)\n",
        "        print('mIoU for validation: %.3f' % miou)\n",
        "        # miou_str = ''\n",
        "        # for key in miou_dict:\n",
        "        #     miou_str += '{}:{},\\n'.format(key, miou_dict[key])\n",
        "        # print('mIoU for each class:')\n",
        "        # print(miou_str)\n",
        "        return precision, miou"
      ],
      "metadata": {
        "id": "gnVsI55NSpcW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## VAL RUBATA\n",
        "def val(args, model, dataloader):\n",
        "    print('start val!')\n",
        "    # label_info = get_label_info(csv_path)\n",
        "    with torch.no_grad():\n",
        "\n",
        "        model.eval()\n",
        "        precision_record = []\n",
        "        tq = tqdm(total=len(dataloader) * 1)\n",
        "        tq.set_description('eval')\n",
        "        hist = np.zeros((args.num_classes, args.num_classes))\n",
        "        for i, (data, label) in enumerate(dataloader):\n",
        "            tq.update(1)\n",
        "            if torch.cuda.is_available() and args.use_gpu:\n",
        "                data = data.cuda()\n",
        "                label = label.cuda()\n",
        "            print(\"DATA\", data)\n",
        "            print(\"data.SHAPE\", data.shape)\n",
        "            print(\"label\", label.shape)\n",
        "\n",
        "            print(\"model(data)\", model(data))\n",
        "            predict = model(data).squeeze()\n",
        "            print(\"predict_squeeze\", predict)\n",
        "            predict = reverse_one_hot(predict)\n",
        "            print(\"predict_reverse_one_hot\", predict)\n",
        "            predict = np.array(predict.cpu())\n",
        "\n",
        "            # get RGB label image\n",
        "            label = label.squeeze()\n",
        "            # if args.loss == 'dice':\n",
        "            # label = reverse_one_hot(label)\n",
        "            label = np.array(label.cpu())\n",
        "\n",
        "            # compute per pixel accuracy\n",
        "            precision = compute_global_accuracy(predict, label)\n",
        "            hist += fast_hist(label.flatten(), predict.flatten(), args.num_classes)\n",
        "\n",
        "            # there is no need to transform the one-hot array to visual RGB array\n",
        "            # predict = colour_code_segmentation(np.array(predict), label_info)\n",
        "            # label = colour_code_segmentation(np.array(label), label_info)\n",
        "            precision_record.append(precision)\n",
        "\n",
        "        precision = np.mean(precision_record)\n",
        "        # miou = np.mean(per_class_iu(hist))\n",
        "        # miou_list = per_class_iu(hist)[:-1]\n",
        "        miou_list = per_class_iu(hist)\n",
        "        # miou_dict, miou = cal_miou(miou_list, csv_path)\n",
        "        miou = np.mean(miou_list)\n",
        "        print('precision per pixel for test: %.3f' % precision)\n",
        "        print('mIoU for validation: %.3f' % miou)\n",
        "        # miou_str = ''\n",
        "        # for key in miou_dict:\n",
        "        # miou_str += '{}:{},\\n'.format(key, miou_dict[key])\n",
        "        # print('mIoU for each class:')\n",
        "        # print(miou_str)\n",
        "        return precision, miou"
      ],
      "metadata": {
        "id": "VsdJ6ibRoiTU"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## -- TRAINING --\n",
        "\n",
        "def train(args, model, optimizer, dataloader_train, dataloader_val):\n",
        "    writer = SummaryWriter(comment=''.format(args.optimizer, args.context_path))\n",
        "\n",
        "    scaler = amp.GradScaler()\n",
        "\n",
        "    if args.loss == 'dice':\n",
        "        loss_func = DiceLoss()\n",
        "    elif args.loss == 'crossentropy':\n",
        "        loss_func = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
        "    \n",
        "    max_miou = 0\n",
        "    step = 0\n",
        "    \n",
        "    for epoch in range(args.num_epochs):\n",
        "        lr = poly_lr_scheduler(optimizer, args.learning_rate, iter=epoch, max_iter=args.num_epochs)\n",
        "        model.train()\n",
        "        tq = tqdm(total=len(dataloader_train) * args.batch_size)\n",
        "        tq.set_description('epoch %d, lr %f' % (epoch, lr))\n",
        "        loss_record = []\n",
        "        for i, (data, label) in enumerate(dataloader_train):\n",
        "            data = data.cuda()\n",
        "            label = label.long().cuda()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            with amp.autocast():\n",
        "                output, output_sup1, output_sup2 = model(data)\n",
        "                loss1 = loss_func(output, label)\n",
        "                loss2 = loss_func(output_sup1, label)\n",
        "                loss3 = loss_func(output_sup2, label)\n",
        "                loss = loss1 + loss2 + loss3\n",
        "            \n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            \n",
        "            tq.update(args.batch_size)\n",
        "            tq.set_postfix(loss='%.6f' % loss)\n",
        "            step += 1\n",
        "            writer.add_scalar('loss_step', loss, step)\n",
        "            loss_record.append(loss.item())\n",
        "            \n",
        "        tq.close()\n",
        "        loss_train_mean = np.mean(loss_record)\n",
        "        writer.add_scalar('epoch/loss_epoch_train', float(loss_train_mean), epoch)\n",
        "        print('loss for train : %f' % (loss_train_mean))\n",
        "        if epoch % args.checkpoint_step == 0 and epoch != 0:\n",
        "            import os\n",
        "            if not os.path.isdir(args.save_model_path):\n",
        "                os.mkdir(args.save_model_path)\n",
        "            torch.save(model.module.state_dict(),\n",
        "                       os.path.join(args.save_model_path, 'latest_dice_loss.pth'))\n",
        "\n",
        "        if epoch % args.validation_step == 0 and epoch != 0:\n",
        "            precision, miou = val(args, model, dataloader_val)\n",
        "            if miou > max_miou:\n",
        "                max_miou = miou\n",
        "                import os \n",
        "                os.makedirs(args.save_model_path, exist_ok=True)\n",
        "                torch.save(model.module.state_dict(),\n",
        "                           os.path.join(args.save_model_path, 'best_dice_loss.pth'))\n",
        "            writer.add_scalar('epoch/precision_val', precision, epoch)\n",
        "            writer.add_scalar('epoch/miou val', miou, epoch)"
      ],
      "metadata": {
        "id": "quVpMD_PSwJS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(params):\n",
        "    # basic parameters\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--num_epochs', type=int, default=300, help='Number of epochs to train for')\n",
        "    parser.add_argument('--epoch_start_i', type=int, default=0, help='Start counting epochs from this number')\n",
        "    parser.add_argument('--checkpoint_step', type=int, default=10, help='How often to save checkpoints (epochs)')\n",
        "    parser.add_argument('--validation_step', type=int, default=10, help='How often to perform validation (epochs)')\n",
        "    parser.add_argument('--dataset', type=str, default=\"Cityscapes\", help='Dataset you are using.')\n",
        "    parser.add_argument('--crop_height', type=int, default=720, help='Height of cropped/resized input image to network')\n",
        "    parser.add_argument('--crop_width', type=int, default=960, help='Width of cropped/resized input image to network')\n",
        "    parser.add_argument('--batch_size', type=int, default=32, help='Number of images in each batch')\n",
        "    parser.add_argument(\"--iter-size\", type=int, default=1, help=\"Accumulate gradients for ITER_SIZE iterations.\")\n",
        "    parser.add_argument('--context_path', type=str, default=\"resnet101\",\n",
        "                        help='The context path model you are using, resnet18, resnet101.')\n",
        "    parser.add_argument('--learning_rate', type=float, default=0.01, help='learning rate used for train')\n",
        "    parser.add_argument('--data', type=str, default='content/data', help='path of training data')\n",
        "    #parser.add_argument(\"--data-list\", type=str, default='/gdrive/MyDrive/data/Cityscapes/train.txt', help=\"Path to the file listing the images in the source dataset.\")\n",
        "    #parser.add_argument(\"--data-list-val\", type=str, default='/gdrive/MyDrive/data/Cityscapes/val.txt', help=\"Path to the file listing the image in the test subset.\")\n",
        "    parser.add_argument('--num_workers', type=int, default=4, help='num of workers')\n",
        "    parser.add_argument('--num_classes', type=int, default=32, help='num of object classes (with void)')\n",
        "    parser.add_argument(\"--num-steps\", type=int, default=250000, help=\"Number of training steps.\")\n",
        "    parser.add_argument('--cuda', type=str, default='0', help='GPU ids used for training')\n",
        "    parser.add_argument('--use_gpu', type=bool, default=True, help='whether to user gpu for training')\n",
        "    parser.add_argument('--pretrained_model_path', type=str, default=None, help='path to pretrained model')\n",
        "    parser.add_argument('--save_model_path', type=str, default=None, help='path to save model')\n",
        "    parser.add_argument('--optimizer', type=str, default='rmsprop', help='optimizer, support rmsprop, sgd, adam')\n",
        "    parser.add_argument('--loss', type=str, default='crossentropy', help='loss function, dice or crossentropy')\n",
        "    parser.add_argument(\"--random-scale\", action=\"store_true\", help=\"Whether to randomly scale the inputs during the training.\")\n",
        "    parser.add_argument(\"--random-mirror\", action=\"store_true\", help=\"Whether to randomly mirror the inputs during the training.\")\n",
        "    parser.add_argument(\"--set-type\", type=str, default='train', help=\"choose adaptation set.\")\n",
        "\n",
        "    args = parser.parse_args(params)\n",
        "\n",
        "    # create dataset and dataloader\n",
        "    data_root_path = os.path.join(args.data, args.dataset) # /content/data/Cityscapes\n",
        "    train_path = os.path.join(data_root_path, \"train.txt\") # /content/data/Cityscapes/train.txt\n",
        "    val_path = os.path.join(data_root_path, \"val.txt\")   # /content/data/Cityscapes/val.txt\n",
        "    info_path = os.path.join(args.data, args.dataset, \"info.json\") # /content/data/Cityscapes/info.json \n",
        "    \n",
        "    # preprocessing informations:\n",
        "    input_size = (int(args.crop_height), int(args.crop_width))\n",
        "    f = open(info_path)\n",
        "    info = json.load(f)\n",
        "    img_mean = info[\"mean\"] # [73.15835921071155, 82.90891754262586, 72.39239876194159]  -> TODO: ask the tutor\n",
        "    img_mean = np.array(img_mean, dtype=np.float32)\n",
        "    #img_mean = np.array((104.00698793, 116.66876762, 122.67891434), dtype=np.float32)\n",
        "    #img_mean=(128, 128, 128)\n",
        "\n",
        "    \n",
        "    # create dataloaders\n",
        "    train_dataset = cityscapesDataSet(root=data_root_path,\n",
        "                                      list_path = train_path,\n",
        "                                      info_json = info,\n",
        "                                      crop_size=input_size,\n",
        "                                      scale=args.random_scale, \n",
        "                                      mirror=args.random_mirror, \n",
        "                                      mean=img_mean)\n",
        "   \n",
        "    \n",
        "    val_dataset = cityscapesDataSet(root=data_root_path,\n",
        "                                    list_path = val_path,\n",
        "                                    info_json = info,\n",
        "                                    crop_size=input_size,\n",
        "                                    scale=False,\n",
        "                                    mirror=args.random_mirror, \n",
        "                                    mean=img_mean)\n",
        "    \n",
        "    print(f'train_dataset: {len(train_dataset)}')\n",
        "    print(f'val_dataset: {len(val_dataset)}')\n",
        "    image, label = train_dataset[0]\n",
        "    print(f'images shape: {image.shape}')\n",
        "    print(f'label shape: {label.shape}')\n",
        "    \n",
        "    # Define dataloaders\n",
        "    dataloader_train = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, pin_memory=True)\n",
        "    \n",
        "    dataloader_val = DataLoader(val_dataset, batch_size=1, shuffle=True, num_workers=args.num_workers, pin_memory=True)\n",
        "    \n",
        "    # build model\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = args.cuda\n",
        "    \n",
        "    model = BiSeNet(args.num_classes, args.context_path)\n",
        "    \n",
        "    if torch.cuda.is_available() and args.use_gpu:\n",
        "        model = torch.nn.DataParallel(model).cuda()\n",
        "\n",
        "    # build optimizer\n",
        "    if args.optimizer == 'rmsprop':\n",
        "        optimizer = torch.optim.RMSprop(model.parameters(), args.learning_rate)\n",
        "    elif args.optimizer == 'sgd':\n",
        "        optimizer = torch.optim.SGD(model.parameters(), args.learning_rate, momentum=0.9, weight_decay=1e-4)\n",
        "    elif args.optimizer == 'adam':\n",
        "        optimizer = torch.optim.Adam(model.parameters(), args.learning_rate)\n",
        "    else:  # rmsprop\n",
        "        print('not supported optimizer \\n')\n",
        "        return None\n",
        "\n",
        "    # load pretrained model if exists\n",
        "    if args.pretrained_model_path is not None:\n",
        "        print('load model from %s ...' % args.pretrained_model_path)\n",
        "        model.module.load_state_dict(torch.load(args.pretrained_model_path))\n",
        "        print('Done!')\n",
        "\n",
        "    # train\n",
        "    train(args, model, optimizer, dataloader_train, dataloader_val)\n",
        "\n",
        "    val(args, model, dataloader_val)\n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "8X0hpXG5S0ta"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%tensorboard --logdir=runs"
      ],
      "metadata": {
        "id": "XbPSPiAYzYJ3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    params = [\n",
        "        '--num_epochs', '1',\n",
        "        '--learning_rate', '2.5e-2',\n",
        "        '--data', data_path,\n",
        "        '--num_workers', '4',\n",
        "        '--num_classes', '19',\n",
        "        '--cuda', '0',\n",
        "        '--batch_size', '2',\n",
        "        '--save_model_path', '/gdrive/MyDrive/Project_AML/Models/checkpoints_101_adam',\n",
        "        '--context_path', 'resnet101',  # set resnet18 or resnet101, only support resnet18 and resnet101\n",
        "        '--optimizer', 'adam',\n",
        "\n",
        "    ]\n",
        "    main(params)"
      ],
      "metadata": {
        "id": "ryuEeQcMS4R5",
        "outputId": "6a60d423-ab21-49d1-bab9-d354abe0c37c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_dataset: 10\n",
            "val_dataset: 10\n",
            "images shape: (3, 960, 720)\n",
            "label shape: (960, 720)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 0, lr 0.025000:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 0, lr 0.025000:  20%|██        | 2/10 [00:05<00:22,  2.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 0, lr 0.025000:  20%|██        | 2/10 [00:05<00:22,  2.80s/it, loss=9.633451]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 0, lr 0.025000:  40%|████      | 4/10 [00:09<00:13,  2.33s/it, loss=9.633451]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 0, lr 0.025000:  40%|████      | 4/10 [00:09<00:13,  2.33s/it, loss=7.710802]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 0, lr 0.025000:  60%|██████    | 6/10 [00:13<00:08,  2.21s/it, loss=7.710802]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 0, lr 0.025000:  60%|██████    | 6/10 [00:13<00:08,  2.21s/it, loss=6.188970]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 0, lr 0.025000:  80%|████████  | 8/10 [00:17<00:04,  2.07s/it, loss=6.188970]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 0, lr 0.025000:  80%|████████  | 8/10 [00:17<00:04,  2.07s/it, loss=7.597576]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 0, lr 0.025000: 100%|██████████| 10/10 [00:21<00:00,  2.03s/it, loss=7.597576]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 0, lr 0.025000: 100%|██████████| 10/10 [00:21<00:00,  2.16s/it, loss=8.237226]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for train : 7.873605\n",
            "start val!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "eval:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "eval:  10%|█         | 1/10 [00:00<00:08,  1.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA tensor([[[[-34.1584, -30.1584, -28.1584,  ..., -29.1584, -21.1584, -60.1584],\n",
            "          [-12.1584, -14.1584, -17.1584,  ..., -30.1584, -23.1584, -61.1584],\n",
            "          [-15.1584, -17.1584, -20.1584,  ..., -31.1584, -24.1584, -61.1584],\n",
            "          ...,\n",
            "          [ -8.1584,  -7.1584,  -7.1584,  ..., -32.1584, -20.1584,  -8.1584],\n",
            "          [ -8.1584,  -7.1584,  -7.1584,  ..., -36.1584, -34.1584, -17.1584],\n",
            "          [ -8.1584,  -7.1584,  -7.1584,  ..., -37.1584, -38.1584, -36.1584]],\n",
            "\n",
            "         [[-22.9089, -22.9089, -21.9089,  ..., -35.9089, -27.9089, -67.9089],\n",
            "          [ -7.9089,  -9.9089, -13.9089,  ..., -36.9089, -29.9089, -67.9089],\n",
            "          [-25.9089, -25.9089, -25.9089,  ..., -37.9089, -30.9089, -68.9089],\n",
            "          ...,\n",
            "          [  0.0911,  -1.9089,  -0.9089,  ..., -35.9089, -19.9089,  -1.9089],\n",
            "          [  0.0911,  -1.9089,  -0.9089,  ..., -39.9089, -38.9089, -14.9089],\n",
            "          [  0.0911,  -1.9089,  -0.9089,  ..., -40.9089, -41.9089, -40.9089]],\n",
            "\n",
            "         [[-38.3924, -34.3924, -29.3924,  ..., -25.3924, -15.3924, -46.3924],\n",
            "          [ -7.3924, -10.3924, -14.3924,  ..., -26.3924, -16.3924, -47.3924],\n",
            "          [-14.3924, -17.3924, -19.3924,  ..., -27.3924, -18.3924, -48.3924],\n",
            "          ...,\n",
            "          [  0.6076,  -0.3924,  -0.3924,  ..., -33.3924, -17.3924,   0.6076],\n",
            "          [  0.6076,  -0.3924,  -0.3924,  ..., -38.3924, -36.3924, -13.3924],\n",
            "          [  0.6076,  -0.3924,  -0.3924,  ..., -39.3924, -40.3924, -39.3924]]]],\n",
            "       device='cuda:0')\n",
            "data.SHAPE torch.Size([1, 3, 960, 720])\n",
            "label torch.Size([1, 960, 720])\n",
            "model(data) tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0')\n",
            "predict_squeeze tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
            "predict_reverse_one_hot tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "eval:  20%|██        | 2/10 [00:02<00:08,  1.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA tensor([[[[-46.1584, -46.1584, -48.1584,  ..., -14.1584,   1.8416, -50.1584],\n",
            "          [-65.1584, -62.1584, -59.1584,  ..., -13.1584,   1.8416, -48.1584],\n",
            "          [-67.1584, -65.1584, -62.1584,  ..., -12.1584,   0.8416, -47.1584],\n",
            "          ...,\n",
            "          [-26.1584, -27.1584, -32.1584,  ..., -36.1584, -32.1584, -28.1584],\n",
            "          [-26.1584, -27.1584, -32.1584,  ..., -34.1584, -34.1584, -30.1584],\n",
            "          [-26.1584, -27.1584, -32.1584,  ..., -34.1584, -34.1584, -34.1584]],\n",
            "\n",
            "         [[-59.9089, -58.9089, -58.9089,  ...,  -9.9089,  -2.9089, -54.9089],\n",
            "          [-64.9089, -63.9089, -61.9089,  ...,  -8.9089,  -2.9089, -52.9089],\n",
            "          [-64.9089, -63.9089, -61.9089,  ...,  -7.9089,  -2.9089, -51.9089],\n",
            "          ...,\n",
            "          [-33.9089, -34.9089, -39.9089,  ..., -45.9089, -39.9089, -33.9089],\n",
            "          [-33.9089, -35.9089, -39.9089,  ..., -43.9089, -43.9089, -37.9089],\n",
            "          [-33.9089, -35.9089, -39.9089,  ..., -44.9089, -44.9089, -43.9089]],\n",
            "\n",
            "         [[-51.3924, -51.3924, -50.3924,  ...,  16.6076,   4.6076, -58.3924],\n",
            "          [-57.3924, -56.3924, -55.3924,  ...,  16.6076,   3.6076, -57.3924],\n",
            "          [-63.3924, -61.3924, -58.3924,  ...,  16.6076,   2.6076, -55.3924],\n",
            "          ...,\n",
            "          [-35.3924, -35.3924, -39.3924,  ..., -44.3924, -39.3924, -33.3924],\n",
            "          [-35.3924, -35.3924, -39.3924,  ..., -44.3924, -43.3924, -37.3924],\n",
            "          [-35.3924, -35.3924, -39.3924,  ..., -44.3924, -44.3924, -43.3924]]]],\n",
            "       device='cuda:0')\n",
            "data.SHAPE torch.Size([1, 3, 960, 720])\n",
            "label torch.Size([1, 960, 720])\n",
            "model(data) tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0')\n",
            "predict_squeeze tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
            "predict_reverse_one_hot tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "eval:  30%|███       | 3/10 [00:02<00:06,  1.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA tensor([[[[ 89.8416,  89.8416,  89.8416,  ..., 104.8416, 104.8416, 104.8416],\n",
            "          [ 89.8416,  90.8416,  90.8416,  ..., 103.8416, 104.8416, 102.8416],\n",
            "          [ 89.8416,  89.8416,  90.8416,  ..., 102.8416, 103.8416, 102.8416],\n",
            "          ...,\n",
            "          [-48.1584, -49.1584, -49.1584,  ..., -26.1584, -26.1584, -29.1584],\n",
            "          [-49.1584, -49.1584, -49.1584,  ..., -25.1584, -25.1584, -26.1584],\n",
            "          [-49.1584, -49.1584, -49.1584,  ..., -24.1584, -24.1584, -24.1584]],\n",
            "\n",
            "         [[ 65.0911,  66.0911,  66.0911,  ...,  77.0911,  77.0911,  79.0911],\n",
            "          [ 66.0911,  67.0911,  67.0911,  ...,  77.0911,  77.0911,  77.0911],\n",
            "          [ 66.0911,  66.0911,  67.0911,  ...,  78.0911,  78.0911,  79.0911],\n",
            "          ...,\n",
            "          [-51.9089, -56.9089, -58.9089,  ..., -22.9089, -23.9089, -26.9089],\n",
            "          [-52.9089, -56.9089, -58.9089,  ..., -21.9089, -21.9089, -23.9089],\n",
            "          [-52.9089, -56.9089, -58.9089,  ..., -20.9089, -20.9089, -22.9089]],\n",
            "\n",
            "         [[ 40.6076,  39.6076,  39.6076,  ...,  44.6076,  44.6076,  46.6076],\n",
            "          [ 40.6076,  39.6076,  40.6076,  ...,  44.6076,  43.6076,  43.6076],\n",
            "          [ 40.6076,  40.6076,  39.6076,  ...,  45.6076,  44.6076,  46.6076],\n",
            "          ...,\n",
            "          [-51.3924, -56.3924, -56.3924,  ..., -24.3924, -26.3924, -29.3924],\n",
            "          [-52.3924, -56.3924, -56.3924,  ..., -25.3924, -24.3924, -26.3924],\n",
            "          [-52.3924, -56.3924, -56.3924,  ..., -24.3924, -24.3924, -24.3924]]]],\n",
            "       device='cuda:0')\n",
            "data.SHAPE torch.Size([1, 3, 960, 720])\n",
            "label torch.Size([1, 960, 720])\n",
            "model(data) tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0')\n",
            "predict_squeeze tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
            "predict_reverse_one_hot tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "eval:  40%|████      | 4/10 [00:03<00:05,  1.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA tensor([[[[ 48.8416,  48.8416,  45.8416,  ..., -32.1584, -31.1584, -28.1584],\n",
            "          [ 48.8416,  48.8416,  46.8416,  ..., -31.1584, -29.1584, -26.1584],\n",
            "          [ 46.8416,  48.8416,  47.8416,  ..., -31.1584, -27.1584, -27.1584],\n",
            "          ...,\n",
            "          [ -8.1584,  -7.1584,  -5.1584,  ..., -26.1584, -27.1584, -29.1584],\n",
            "          [ -8.1584,  -7.1584,  -5.1584,  ..., -24.1584, -24.1584, -26.1584],\n",
            "          [ -8.1584,  -7.1584,  -5.1584,  ..., -24.1584, -24.1584, -25.1584]],\n",
            "\n",
            "         [[ 44.0911,  42.0911,  40.0911,  ..., -33.9089, -32.9089, -28.9089],\n",
            "          [ 43.0911,  42.0911,  40.0911,  ..., -33.9089, -30.9089, -27.9089],\n",
            "          [ 41.0911,  43.0911,  40.0911,  ..., -32.9089, -28.9089, -27.9089],\n",
            "          ...,\n",
            "          [ -4.9089,  -4.9089,  -3.9089,  ..., -27.9089, -28.9089, -30.9089],\n",
            "          [ -4.9089,  -4.9089,  -3.9089,  ..., -25.9089, -24.9089, -27.9089],\n",
            "          [ -4.9089,  -4.9089,  -3.9089,  ..., -25.9089, -25.9089, -26.9089]],\n",
            "\n",
            "         [[ 30.6076,  31.6076,  28.6076,  ..., -29.3924, -29.3924, -27.3924],\n",
            "          [ 30.6076,  31.6076,  29.6076,  ..., -28.3924, -27.3924, -24.3924],\n",
            "          [ 30.6076,  31.6076,  30.6076,  ..., -27.3924, -24.3924, -23.3924],\n",
            "          ...,\n",
            "          [-10.3924, -10.3924,  -9.3924,  ..., -31.3924, -31.3924, -32.3924],\n",
            "          [-10.3924, -10.3924,  -9.3924,  ..., -28.3924, -28.3924, -29.3924],\n",
            "          [-10.3924, -10.3924,  -9.3924,  ..., -28.3924, -29.3924, -28.3924]]]],\n",
            "       device='cuda:0')\n",
            "data.SHAPE torch.Size([1, 3, 960, 720])\n",
            "label torch.Size([1, 960, 720])\n",
            "model(data) tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0')\n",
            "predict_squeeze tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
            "predict_reverse_one_hot tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "eval:  50%|█████     | 5/10 [00:04<00:04,  1.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA tensor([[[[-67.1584, -63.1584, -60.1584,  ..., -21.1584, -18.1584, -45.1584],\n",
            "          [-71.1584, -69.1584, -64.1584,  ..., -22.1584, -19.1584, -45.1584],\n",
            "          [-54.1584, -54.1584, -53.1584,  ..., -23.1584, -20.1584, -45.1584],\n",
            "          ...,\n",
            "          [ 10.8416,  10.8416,   9.8416,  ..., -18.1584,  -5.1584,   8.8416],\n",
            "          [ 10.8416,  10.8416,   9.8416,  ..., -18.1584, -17.1584,  -0.1584],\n",
            "          [ 10.8416,  10.8416,   9.8416,  ..., -17.1584, -17.1584, -16.1584]],\n",
            "\n",
            "         [[-54.9089, -54.9089, -53.9089,  ..., -20.9089, -17.9089, -40.9089],\n",
            "          [-62.9089, -59.9089, -57.9089,  ..., -20.9089, -18.9089, -40.9089],\n",
            "          [-47.9089, -49.9089, -50.9089,  ..., -21.9089, -19.9089, -40.9089],\n",
            "          ...,\n",
            "          [ 19.0911,  17.0911,  18.0911,  ..., -19.9089,  -1.9089,  17.0911],\n",
            "          [ 19.0911,  17.0911,  18.0911,  ..., -19.9089, -18.9089,   5.0911],\n",
            "          [ 19.0911,  17.0911,  18.0911,  ..., -17.9089, -18.9089, -18.9089]],\n",
            "\n",
            "         [[-40.3924, -42.3924, -43.3924,  ...,  17.6076,  24.6076,   8.6076],\n",
            "          [-55.3924, -52.3924, -50.3924,  ...,  16.6076,  23.6076,   7.6076],\n",
            "          [-49.3924, -48.3924, -48.3924,  ...,  15.6076,  22.6076,   6.6076],\n",
            "          ...,\n",
            "          [ 18.6076,  15.6076,  17.6076,  ..., -19.3924,  -2.3924,  14.6076],\n",
            "          [ 18.6076,  15.6076,  17.6076,  ..., -18.3924, -17.3924,   4.6076],\n",
            "          [ 18.6076,  15.6076,  17.6076,  ..., -16.3924, -17.3924, -16.3924]]]],\n",
            "       device='cuda:0')\n",
            "data.SHAPE torch.Size([1, 3, 960, 720])\n",
            "label torch.Size([1, 960, 720])\n",
            "model(data) tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0')\n",
            "predict_squeeze tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
            "predict_reverse_one_hot tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "eval:  60%|██████    | 6/10 [00:05<00:03,  1.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA tensor([[[[-70.1584, -70.1584, -69.1584,  ..., -35.1584, -23.1584, -10.1584],\n",
            "          [-42.1584, -43.1584, -43.1584,  ..., -34.1584, -22.1584, -10.1584],\n",
            "          [-46.1584, -45.1584, -44.1584,  ..., -33.1584, -21.1584, -10.1584],\n",
            "          ...,\n",
            "          [ -7.1584,  -5.1584,  -5.1584,  ..., -32.1584, -19.1584,  -4.1584],\n",
            "          [ -7.1584,  -5.1584,  -5.1584,  ..., -28.1584, -27.1584, -11.1584],\n",
            "          [ -6.1584,  -4.1584,  -5.1584,  ..., -16.1584, -17.1584, -17.1584]],\n",
            "\n",
            "         [[-28.9089, -27.9089, -26.9089,  ..., -27.9089, -17.9089,  -4.9089],\n",
            "          [  2.0911,  -2.9089,  -8.9089,  ..., -27.9089, -16.9089,  -4.9089],\n",
            "          [-10.9089, -13.9089, -16.9089,  ..., -26.9089, -15.9089,  -4.9089],\n",
            "          ...,\n",
            "          [ -5.9089,  -5.9089,  -4.9089,  ..., -34.9089, -17.9089,  -0.9089],\n",
            "          [ -5.9089,  -5.9089,  -4.9089,  ..., -27.9089, -26.9089,  -8.9089],\n",
            "          [ -5.9089,  -5.9089,  -4.9089,  ..., -15.9089, -16.9089, -15.9089]],\n",
            "\n",
            "         [[-30.3924, -33.3924, -35.3924,  ...,  21.6076,  -5.3924,  19.6076],\n",
            "          [ -0.3924,  -7.3924, -16.3924,  ...,  20.6076,  -5.3924,  19.6076],\n",
            "          [ -2.3924,  -8.3924, -15.3924,  ...,  19.6076,  -5.3924,  18.6076],\n",
            "          ...,\n",
            "          [ -5.3924,  -6.3924,  -6.3924,  ..., -34.3924, -18.3924,  -0.3924],\n",
            "          [ -5.3924,  -6.3924,  -6.3924,  ..., -29.3924, -28.3924, -10.3924],\n",
            "          [ -5.3924,  -6.3924,  -6.3924,  ..., -13.3924, -14.3924, -15.3924]]]],\n",
            "       device='cuda:0')\n",
            "data.SHAPE torch.Size([1, 3, 960, 720])\n",
            "label torch.Size([1, 960, 720])\n",
            "model(data) tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0')\n",
            "predict_squeeze tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
            "predict_reverse_one_hot tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "eval:  70%|███████   | 7/10 [00:06<00:02,  1.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA tensor([[[[ 77.8416,  80.8416,  83.8416,  ..., -55.1584,  26.8416,  13.8416],\n",
            "          [127.8416, 120.8416, 112.8416,  ..., -54.1584,  27.8416,  13.8416],\n",
            "          [ 65.8416,  72.8416,  82.8416,  ..., -52.1584,  27.8416,  13.8416],\n",
            "          ...,\n",
            "          [-40.1584, -41.1584, -39.1584,  ..., -12.1584, -24.1584, -37.1584],\n",
            "          [-40.1584, -41.1584, -39.1584,  ...,  -9.1584, -11.1584, -29.1584],\n",
            "          [-40.1584, -41.1584, -39.1584,  ...,  -7.1584,  -7.1584,  -8.1584]],\n",
            "\n",
            "         [[132.0911, 128.0911, 125.0911,  ..., -52.9089,  31.0911,  23.0911],\n",
            "          [151.0911, 145.0911, 138.0911,  ..., -51.9089,  31.0911,  23.0911],\n",
            "          [ 67.0911,  79.0911,  95.0911,  ..., -49.9089,  31.0911,  23.0911],\n",
            "          ...,\n",
            "          [-46.9089, -46.9089, -47.9089,  ..., -17.9089, -32.9089, -46.9089],\n",
            "          [-46.9089, -46.9089, -47.9089,  ..., -17.9089, -19.9089, -37.9089],\n",
            "          [-46.9089, -46.9089, -47.9089,  ..., -17.9089, -17.9089, -18.9089]],\n",
            "\n",
            "         [[160.6076, 153.6076, 146.6076,  ..., -68.3924,  22.6076,  42.6076],\n",
            "          [163.6076, 158.6076, 151.6076,  ..., -67.3924,  21.6076,  41.6076],\n",
            "          [ 66.6076,  81.6076, 102.6076,  ..., -67.3924,  21.6076,  41.6076],\n",
            "          ...,\n",
            "          [-44.3924, -44.3924, -45.3924,  ..., -24.3924, -34.3924, -44.3924],\n",
            "          [-44.3924, -44.3924, -45.3924,  ..., -22.3924, -22.3924, -37.3924],\n",
            "          [-44.3924, -44.3924, -45.3924,  ..., -22.3924, -21.3924, -22.3924]]]],\n",
            "       device='cuda:0')\n",
            "data.SHAPE torch.Size([1, 3, 960, 720])\n",
            "label torch.Size([1, 960, 720])\n",
            "model(data) tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0')\n",
            "predict_squeeze tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
            "predict_reverse_one_hot tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "eval:  80%|████████  | 8/10 [00:07<00:01,  1.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA tensor([[[[-73.1584, -73.1584, -70.1584,  ...,  11.8416, -73.1584, -73.1584],\n",
            "          [-73.1584, -73.1584, -72.1584,  ...,  10.8416, -73.1584, -73.1584],\n",
            "          [-73.1584, -73.1584, -69.1584,  ...,   9.8416, -73.1584, -73.1584],\n",
            "          ...,\n",
            "          [ 19.8416,  20.8416,  19.8416,  ...,  29.8416,  23.8416,  16.8416],\n",
            "          [ 19.8416,  20.8416,  19.8416,  ...,  29.8416,  29.8416,  20.8416],\n",
            "          [ 20.8416,  20.8416,  19.8416,  ...,  29.8416,  29.8416,  29.8416]],\n",
            "\n",
            "         [[-82.9089, -73.9089, -45.9089,  ...,   9.0911, -82.9089, -82.9089],\n",
            "          [-80.9089, -77.9089, -63.9089,  ...,   8.0911, -82.9089, -82.9089],\n",
            "          [-71.9089, -53.9089, -35.9089,  ...,   7.0911, -82.9089, -82.9089],\n",
            "          ...,\n",
            "          [ 22.0911,  22.0911,  21.0911,  ...,  33.0911,  26.0911,  20.0911],\n",
            "          [ 22.0911,  22.0911,  21.0911,  ...,  33.0911,  32.0911,  24.0911],\n",
            "          [ 22.0911,  22.0911,  21.0911,  ...,  33.0911,  33.0911,  32.0911]],\n",
            "\n",
            "         [[-72.3924, -72.3924, -66.3924,  ..., -72.3924, -72.3924, -71.3924],\n",
            "          [-72.3924, -72.3924, -69.3924,  ..., -72.3924, -72.3924, -63.3924],\n",
            "          [-72.3924, -70.3924, -54.3924,  ..., -72.3924, -72.3924, -58.3924],\n",
            "          ...,\n",
            "          [ 18.6076,  18.6076,  17.6076,  ...,  34.6076,  25.6076,  17.6076],\n",
            "          [ 18.6076,  18.6076,  17.6076,  ...,  32.6076,  32.6076,  22.6076],\n",
            "          [ 18.6076,  18.6076,  17.6076,  ...,  31.6076,  32.6076,  31.6076]]]],\n",
            "       device='cuda:0')\n",
            "data.SHAPE torch.Size([1, 3, 960, 720])\n",
            "label torch.Size([1, 960, 720])\n",
            "model(data) tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0')\n",
            "predict_squeeze tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
            "predict_reverse_one_hot tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "eval:  90%|█████████ | 9/10 [00:08<00:00,  1.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA tensor([[[[ 24.8416,  23.8416,  20.8416,  ...,  92.8416,  93.8416,  96.8416],\n",
            "          [ 26.8416,  26.8416,  25.8416,  ...,  92.8416,  93.8416,  96.8416],\n",
            "          [ 27.8416,  26.8416,  25.8416,  ...,  92.8416,  95.8416,  95.8416],\n",
            "          ...,\n",
            "          [-31.1584, -30.1584, -30.1584,  ..., -32.1584, -33.1584, -32.1584],\n",
            "          [-31.1584, -30.1584, -30.1584,  ..., -35.1584, -36.1584, -35.1584],\n",
            "          [-31.1584, -30.1584, -30.1584,  ..., -39.1584, -38.1584, -37.1584]],\n",
            "\n",
            "         [[ 31.0911,  32.0911,  31.0911,  ..., 105.0911, 106.0911, 107.0911],\n",
            "          [ 33.0911,  34.0911,  34.0911,  ..., 105.0911, 106.0911, 107.0911],\n",
            "          [ 33.0911,  34.0911,  33.0911,  ..., 105.0911, 107.0911, 106.0911],\n",
            "          ...,\n",
            "          [-33.9089, -31.9089, -30.9089,  ..., -35.9089, -36.9089, -36.9089],\n",
            "          [-33.9089, -31.9089, -30.9089,  ..., -39.9089, -38.9089, -39.9089],\n",
            "          [-33.9089, -31.9089, -30.9089,  ..., -42.9089, -42.9089, -42.9089]],\n",
            "\n",
            "         [[ 27.6076,  27.6076,  25.6076,  ...,  95.6076,  96.6076,  94.6076],\n",
            "          [ 28.6076,  27.6076,  27.6076,  ...,  95.6076,  96.6076,  96.6076],\n",
            "          [ 26.6076,  27.6076,  27.6076,  ...,  96.6076,  97.6076,  97.6076],\n",
            "          ...,\n",
            "          [-35.3924, -33.3924, -32.3924,  ..., -36.3924, -36.3924, -36.3924],\n",
            "          [-35.3924, -33.3924, -32.3924,  ..., -39.3924, -38.3924, -39.3924],\n",
            "          [-35.3924, -33.3924, -32.3924,  ..., -42.3924, -41.3924, -42.3924]]]],\n",
            "       device='cuda:0')\n",
            "data.SHAPE torch.Size([1, 3, 960, 720])\n",
            "label torch.Size([1, 960, 720])\n",
            "model(data) tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0')\n",
            "predict_squeeze tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
            "predict_reverse_one_hot tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "eval: 100%|██████████| 10/10 [00:09<00:00,  1.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA tensor([[[[-22.1584, -23.1584, -24.1584,  ..., -44.1584, -46.1584, -46.1584],\n",
            "          [-24.1584, -24.1584, -22.1584,  ..., -44.1584, -45.1584, -45.1584],\n",
            "          [-29.1584, -28.1584, -26.1584,  ..., -44.1584, -45.1584, -44.1584],\n",
            "          ...,\n",
            "          [-15.1584, -14.1584, -14.1584,  ..., -33.1584, -34.1584, -35.1584],\n",
            "          [-15.1584, -14.1584, -14.1584,  ..., -29.1584, -30.1584, -31.1584],\n",
            "          [-15.1584, -14.1584, -14.1584,  ..., -27.1584, -27.1584, -27.1584]],\n",
            "\n",
            "         [[-19.9089, -18.9089, -17.9089,  ..., -49.9089, -51.9089, -50.9089],\n",
            "          [-20.9089, -19.9089, -17.9089,  ..., -48.9089, -50.9089, -50.9089],\n",
            "          [-26.9089, -23.9089, -20.9089,  ..., -47.9089, -49.9089, -49.9089],\n",
            "          ...,\n",
            "          [-14.9089, -13.9089, -13.9089,  ..., -33.9089, -34.9089, -36.9089],\n",
            "          [-14.9089, -13.9089, -13.9089,  ..., -28.9089, -30.9089, -32.9089],\n",
            "          [-14.9089, -13.9089, -13.9089,  ..., -27.9089, -27.9089, -28.9089]],\n",
            "\n",
            "         [[-12.3924, -13.3924, -12.3924,  ..., -48.3924, -49.3924, -49.3924],\n",
            "          [-13.3924, -14.3924, -10.3924,  ..., -46.3924, -48.3924, -48.3924],\n",
            "          [-17.3924, -17.3924, -12.3924,  ..., -45.3924, -48.3924, -47.3924],\n",
            "          ...,\n",
            "          [-18.3924, -18.3924, -19.3924,  ..., -35.3924, -36.3924, -37.3924],\n",
            "          [-18.3924, -18.3924, -19.3924,  ..., -30.3924, -31.3924, -32.3924],\n",
            "          [-18.3924, -18.3924, -19.3924,  ..., -29.3924, -28.3924, -27.3924]]]],\n",
            "       device='cuda:0')\n",
            "data.SHAPE torch.Size([1, 3, 960, 720])\n",
            "label torch.Size([1, 960, 720])\n",
            "model(data) tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0')\n",
            "predict_squeeze tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0')\n",
            "predict_reverse_one_hot tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\reval: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision per pixel for test: 0.295\n",
            "mIoU for validation: 0.017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.memory_summary()\n",
        "#torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "74xLh4HqXQT2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}